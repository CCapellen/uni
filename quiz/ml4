Q: What is Bayes Theorem?
A: 
Q: What is MAP?
A:
Q: What is ML?
A:
Q: Describe the Brute Force MAP Hypothesis Learner Algorithm
A:
Q: What do they mean with ML minimizes the sum of squared errors?
A:
Q: Describe the Bayes optimal classifier.
A: arg max_{v_j \in V} \sum_{h_i \in H} P(v_j|h_i) * P(h_i|D) with v_j a possible class, h_i a hypothesis and data D.
Q: Describe and derive the Naive Bayes Classifier and algorithm. What might cause Problems? 
A: v = argmax_{v_j \in V} P(v_j) \product_i P(a_i|v_j); conditional independenceassumption is often violated, but it still might work quite well; It's possible that none of the training instances with a target calue v_j have attribute value a_i and then P(a_i|v_j) = 0.
Q: How can you represent text?
A: Bag-of-Word Approach
Q: What are Bayesian Belief Networks?
A: 


