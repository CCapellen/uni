Q: What is an impurity function for concept learning and which are there?
A: function on p+ and p- being the fraction of positive and negative examples which fulfills for p+ p- from the appropriate range: (i) f(p+,p-) = f(p-,p+) (ii) argmax of f is (0.5,0.5) (iii) argmin of f is (1,0) or (0,1); impurity functions are the Entropy and the Gini coefficient (1-(p+^2 + p-^2))
Q: Prove H(X|Y) \leq H(X). When holds the equality. what does this equation mean?
A: see exercise; equality holds if and only if X and Y are independent; it means that dividing X with a variable Y improves the uncertainty (if they are not independent)
Q: What does the information gain mean informally?
A: Gain(X|Y): How much reduction in entropy would you get by knowing Y
Q: How is Gain Ratio defined, what does it mean and what is the advantage to the information gain?
A: GainRation(S,A) = Gain(S,A)/SplitInfo(S,A) where SplitInfo(S,A) = - \sum_{i=1}^m (|S_i|/|S|) * log_2  (|S_i|/|S|). The SplitInformation is the entropy of S with respect ot the values of A 
Q: How can you determine a good split in a decision tree for continuous variables
A: expert preprocessing, automatic preclustering, search at split time: 1. sort examples covered by the current node according to the calues of A, 2: for all adjacent examples with different classes do: 3: take the mean m of the values of A for the two examples, 4: calculate the information gain for the split A<m for the current node end for; 5: return A<c that maximizes the information gain
